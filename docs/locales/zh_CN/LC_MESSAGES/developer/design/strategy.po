# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Ant Group Co., Ltd.
# This file is distributed under the same license as the SecretFlow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: SecretFlow \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-05-29 19:21+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"

#: ../../developer/design/strategy.md:1
msgid "Strategy Design"
msgstr "Strategy框架设计"

#: ../../developer/design/strategy.md:2
msgid "What is Strategy?"
msgstr "什么是Strategy？"

#: ../../developer/design/strategy.md:3
msgid ""
"The federated learning strategy is the key difference between federated "
"learning and conventional distributed machine learning, and it is "
"critical to the effect of model training. Strategy is mainly composed of "
"two parts in federated learning. One part is the local training strategy "
"of the local part, which includes the control of the loss function (how "
"to align the server side, etc.), how to transmit gradients or parameters "
"upstream; the second part is the server part, It includes how to "
"aggregate gradients or parameters uploaded by Clients, how to update "
"them, and how to distribute them downstream. SecretFlow encapsulates a "
"layer of Strategy under FLModel to control the learning strategy of the "
"model in federated scenarios. The lingo provides Strategy Zoo, which "
"currently supports various strategies covering Non-iid and communication "
"optimization, and is constantly updated iteratively. Users Just pass the "
"alias names of different strategies (\"fed_avg_w\", \"fed_avg_g\", "
"\"fed_prox\", \"fed_scr\", etc.) to complete the call. At the same time, "
"the Strategy framework supports the development, registration, and use of"
" user-defined strategies."
msgstr ""
"联邦学习策略是联邦学习区别于常规分布式机器学习的关键差别，对于模型训练效果影响非常关键。Strategy在联邦学习中主要由两部分组成，一部分是local部分的本地训练策略，其中包含对于loss函数的控制（和server端如何对齐等），梯度或者参数怎么上行传输；第二部分是server部分，包含如何对Clients上传的梯度或参数如何聚合，如何更新，如何下行分发等。SecretFlow在FLModel之下封装了一层Strategy，控制模型在联邦场景下的学习策略，隐语提供了Strategy"
" Zoo，目前已支持涵盖Non-iid和通信优化等多种策略，而且在不断的迭代更新，用户只需要传递不同策略的alias "
"name(\"fed_avg_w\",\"fed_avg_g\",\"fed_prox\",\"fed_scr\"等)，即可完成调用。同时Strategy框架支持用户自定义策略开发、注册、使用等。"

#: ../../developer/design/strategy.md:6
msgid "The positioning and characteristics of SecretFlow's Strategy"
msgstr "SecretFlow的Strategy的定位以及特点"

#: ../../developer/design/strategy.md:7
msgid "Pull up different Workers according to the strategy name"
msgstr "根据strategy name来拉起不同的Workers"

#: ../../developer/design/strategy.md:8
msgid ""
"Define how to perform local calculation in Worker, which parameters (g/w)"
" to upload after calculation, whether to compress, etc."
msgstr "在Worker中定义如何进行local计算，计算完成后要上传哪些参数（g/w），是否压缩等。"

#: ../../developer/design/strategy.md:9
msgid ""
"In FLModel, how to calculate on the server side is determined according "
"to the strategy name."
msgstr "在FLModel中根据strategy name来决定 server端如何计算。"

#: ../../developer/design/strategy.md:10
msgid ""
"Provide a user-friendly interface for users to develop a new strategy for"
" the second time. Users only need to define train_step and provide "
"aggregation logic to complete the development of the strategy. At the "
"same time, only one line of code is required for the user to complete the"
" registration."
msgstr ""
"为用户二次开发新的strategy提供了用户友好的接口，用户只需要定义好train_step，并提供聚合逻辑即可完成strategy的开发， "
"同时只需要用户一行代码就可以完成注册"

#: ../../developer/design/strategy.md:12
msgid "Architecture diagram"
msgstr "架构图"

#: ../../developer/design/strategy.md:13
msgid "Strategy consists of three parts"
msgstr "Strategy中包含了三个部分"

#: ../../developer/design/strategy.md:14
msgid ""
"The calculation logic of the local part of the train step, and the tensor"
" content that needs to be transmitted"
msgstr "local部分 train step的计算逻辑，以及需要传输的tensor内容"

#: ../../developer/design/strategy.md:15
msgid "Compression method for upstream and downstream data transmission"
msgstr "上下行数据传输的压缩方法"

#: ../../developer/design/strategy.md:16
msgid ""
"Aggregation logic in server part ![arch](resources/strategy_arc.jpg) Our "
"secretflow framework also provides a friendly advanced development "
"interface for high-level advanced developers, which can be easily "
"extended to new custom strategy"
msgstr "server部分的聚合逻辑"

#: ../../developer/design/strategy.md:16
msgid "arch"
msgstr "arch"

#: ../../developer/design/strategy.md:19
msgid "Using Built-in Strategy"
msgstr "使用内置Strategy"

#: ../../developer/design/strategy.md:20
msgid ""
"Using the built-in Strategy is very straightforward and simple, the user "
"only needs to pass the name of the strategy method they want to use into "
"\"FLModel\". Currently provided strategies (continuously updated):"
msgstr ""
"使用built-in Strategy是非常直接以及简单的，用户只需要把想要使用的strategy "
"方法名传入\"FLModel\"即可。目前提供的strategy(持续更新中)："

#: ../../developer/design/strategy.md:33
msgid "Custom Strategy"
msgstr "自定义Strategy"

#: ../../developer/design/strategy.md:34
msgid "A custom strategy takes just a few steps"
msgstr "自定义strategy仅需以下几步"

#: ../../developer/design/strategy.md:35
msgid "local train strategy"
msgstr "local train strategy"

#: ../../developer/design/strategy.md:36
msgid "server aggragate strategy （not supported）"
msgstr "server aggragate strategy （not supported）"

#: ../../developer/design/strategy.md:37
msgid "compressor strategy"
msgstr "compressor strategy"

#: ../../developer/design/strategy.md:38 ../../developer/design/strategy.md:97
msgid "register strategy"
msgstr "register strategy"

#: ../../developer/design/strategy.md:39
msgid "The local strategy"
msgstr "The local strategy"

#: ../../developer/design/strategy.md:40
msgid ""
"The local strategy in SecretFlow is a framework on top of fl_base, "
"inherits all the properties and methods of BaseModel, and provides local "
"calculation logic dedicated to a specific strategy"
msgstr ""
"SecretFlow中的local "
"strategy是封装在fl_base之上的一层，继承BaseModel的所有属性和方法，并提供专属与特定strategy 的local 计算逻辑"

#: ../../developer/design/strategy.md:72
msgid "compressor definition"
msgstr "compressor定义"

#: ../../developer/design/strategy.md:73
msgid ""
"Define strategy tensor compression algorithms to speed up transmission. "
"Add the strategy short name you need compress on downlink stage to "
"COMPRESS_STRATEGY, and FLModel will control whether to perform "
"compression when downlinking to the client after aggregation. Client-to-"
"server upstream stage compression can be done in your local training "
"strategy."
msgstr ""
"定义专属与当前strategy的tensor压缩算法，加快传输速度。将您需要进行下行压缩的策略加入COMPRESS_STRATEGY，FLModel会根据判断来决定是否在聚合后下行传输到client的时候进行压缩。client到server的上行阶段压缩，在您的local"
" training strategy中完成即可。"

#: ../../developer/design/strategy.md:106
msgid "Then, update `__init__.py`,to make this strategy effect.   eg:"
msgstr "最后，需要更新`__init__.py`文件，来让新的策略生效"

#: ../../developer/design/strategy.md:108
msgid "secretflow/ml/nn/fl/backend/tensorflow/strategy/\\_\\_init\\_\\_.py"
msgstr "secretflow/ml/nn/fl/backend/tensorflow/strategy/\\_\\_init\\_\\_.py"

#: ../../developer/design/strategy.md:109
msgid "secretflow/ml/nn/fl/backend/torch/strategy/\\_\\_init\\_\\_.py"
msgstr "secretflow/ml/nn/fl/backend/torch/strategy/\\_\\_init\\_\\_.py"

#: ../../developer/design/strategy.md:132
msgid ""
"Until now, the development of custom strategy is completed. You can pass "
"the short name of new strategy into the strategy field of FL_Model to "
"enable the new federated learning strategy."
msgstr "到这里就完成开发了，您可以将构造好新的strategy_name传入FL_Model的strategy字段，就可以启用新的联邦学习策略啦"

